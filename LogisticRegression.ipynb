{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "            Initialize parameters and set step size to zero.\n",
    "        '''\n",
    "\n",
    "        self.w = np.array([0, 0, 0, 0]).T\n",
    "        self.alpha = 0.1\n",
    "\n",
    "        \n",
    "    def load_data(self, trainset_path, mask_path, valimg_path, valmasks_path):\n",
    "        '''\n",
    "            Load the validation set and the training set\n",
    "            \n",
    "            Input:\n",
    "                trainset_path - string with path to training images\n",
    "                mask_path - string with path to training label masks\n",
    "                valimg_path - string with path to validation images\n",
    "                valmasks_path - string with path to validation label masks\n",
    "        '''\n",
    "        # organize validation image data into stack of pixel values i.e. matrix: (# of pixels x 4)\n",
    "        # and organize validation mask data into column of labels, y = {0, 1}\n",
    "        # ---------------------------------------------------------------\n",
    "        # find total number of pixels in validation set so numpy arrays can be initialized\n",
    "        num_pixels = 0\n",
    "        for filename in os.listdir(valmasks_path):\n",
    "            if filename != '.DS_Store':\n",
    "                image = cv2.imread(os.path.join(valmasks_path,filename))\n",
    "                num_pixels += image.shape[0] * image.shape[1]\n",
    "\n",
    "        self.valset = np.zeros((num_pixels, 3))\n",
    "        self.vallabels = np.zeros((num_pixels, 1))\n",
    "        \n",
    "        # fill the valset and vallabel numpy arrays with validation set data\n",
    "        start = 0\n",
    "        for image_filename in os.listdir(valimg_path):\n",
    "            if image_filename != '.DS_Store':\n",
    "                \n",
    "                image = cv2.imread(os.path.join(valimg_path,image_filename))\n",
    "\n",
    "                size = image.shape[0] * image.shape[1]\n",
    "\n",
    "                self.valset[start:start + size, :] = image.reshape((-1,3))\n",
    "                \n",
    "                image_id = re.search(\"\\d+\", image_filename).group()\n",
    "                label_filename = [file for file in os.listdir(valmasks_path) if image_id + '.jpg' == file]\n",
    "\n",
    "                label = cv2.imread(os.path.join(valmasks_path,label_filename[0]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                self.vallabels[start:start + size, :] = label.reshape((-1, 1)) \n",
    "\n",
    "                start += size\n",
    "\n",
    "        # set all vallabels that are nonzero to one and map image data from 0 to 1\n",
    "        self.vallabels[self.vallabels > 0] = 1\n",
    "        self.valset = self.valset / 255\n",
    "        \n",
    "        # add column of ones\n",
    "        self.valset = np.hstack([np.ones([self.valset.shape[0], 1]), self.valset])\n",
    "\n",
    "        print(\"Validation set prepared\")\n",
    "        \n",
    "        # ---------------------------------------------------------------\n",
    "        # organize training data into stack of pixel values i.e. matrix: (# of pixels x 4)\n",
    "        # and organize mask data into column of labels, y = {-1, 1}\n",
    "        # ---------------------------------------------------------------\n",
    "        # find total number of pixels in training set so numpy arrays can be initialized\n",
    "        num_pixels = 0\n",
    "        for filename in os.listdir(mask_path):\n",
    "            if filename != '.DS_Store':\n",
    "                image = cv2.imread(os.path.join(mask_path,filename))\n",
    "                num_pixels += image.shape[0] * image.shape[1]\n",
    "\n",
    "        # initialize numpy arrays\n",
    "        trainset = np.zeros((num_pixels, 3))\n",
    "        labels = np.zeros((num_pixels, 1))\n",
    "\n",
    "        # fill numpy arrays with data\n",
    "        start = 0\n",
    "        for image_filename in os.listdir(trainset_path):\n",
    "            if image_filename != '.DS_Store':\n",
    "                \n",
    "                image = cv2.imread(os.path.join(trainset_path,image_filename))\n",
    "\n",
    "                size = image.shape[0] * image.shape[1]\n",
    "\n",
    "                trainset[start:start + size, :] = image.reshape((-1,3))\n",
    "                \n",
    "                image_id = re.search(\"\\d+\", image_filename).group()\n",
    "                label_filename = [file for file in os.listdir(mask_path) if image_id + '.jpg' == file]\n",
    "\n",
    "                label = cv2.imread(os.path.join(mask_path,label_filename[0]), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                labels[start:start + size, :] = label.reshape((-1, 1)) \n",
    "\n",
    "                start += size\n",
    "           \n",
    "        # set nonzero labels to 1\n",
    "        labels[labels>0] = 1 \n",
    "                \n",
    "        # get only the red pixels in training set\n",
    "        self.red_set = trainset[labels[:,0]>0]\n",
    "        \n",
    "        # Remove white pixels\n",
    "        white_pix = self.red_set > np.array([224, 224, 224])\n",
    "        white_pix = white_pix.astype(int)\n",
    "        white_pix = white_pix.sum(axis=1)\n",
    "        self.red_set = self.red_set[white_pix!=3]\n",
    "        self.red_set = self.red_set / 255\n",
    "        \n",
    "        # add column of ones\n",
    "        self.red_set = np.hstack([np.ones([self.red_set.shape[0], 1]), self.red_set])\n",
    "        \n",
    "        self.red_labels = np.ones((self.red_set.shape[0], 1))\n",
    "        print('red set prepared')\n",
    "        \n",
    "        # get only non red pixels in training set\n",
    "        self.background_set = trainset[labels[:,0]==0]\n",
    "        # only keep same number in background_set as belong in the red_set\n",
    "        self.background_set = self.background_set[:self.red_set.shape[0], :]\n",
    "        self.background_set = self.background_set / 255\n",
    "        \n",
    "        # add column of ones\n",
    "        self.background_set = np.hstack([np.ones([self.background_set.shape[0], 1]), self.background_set])\n",
    "        \n",
    "        # create background_labels of y = -1\n",
    "        self.background_labels = -np.ones((self.background_set.shape[0], 1))\n",
    "        print('background set prepared')\n",
    "        # ---------------------------------------------------------------\n",
    "   \n",
    "    def train_model(self):\n",
    "        '''\n",
    "            Train the logistic regression model with the loaded data.  Use gradient descent to update parameters and \n",
    "            plot accuracy on validation set between each iteration.\n",
    "        '''\n",
    "        \n",
    "        count = 1\n",
    "        self.accuracy = []\n",
    "        # Perform gradient descent\n",
    "        while True:\n",
    "                print('Iteration: ', count)\n",
    "                \n",
    "                # get new parameters\n",
    "                w_new = self.update_parameter(np.vstack((self.red_set, self.background_set)), np.vstack((self.red_labels, self.background_labels)))\n",
    "                print(w_new)\n",
    "                count += 1\n",
    "                \n",
    "                # check if parameters converge\n",
    "                if (np.abs((w_new - self.w)) < np.array([10, 10, 10, 10])).all():\n",
    "                        self.w = w_new\n",
    "                        print('Convergence!')\n",
    "                        break\n",
    "\n",
    "                self.w = w_new\n",
    "                \n",
    "                # plot accuracy\n",
    "                self.accuracy.append(self.validate())\n",
    "                print('accuracy: ', self.accuracy)\n",
    "                plt.plot(range(count-1), self.accuracy)\n",
    "                plt.xlabel('Iterations')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.title('Accuracy of Segmentation')\n",
    "                plt.show()\n",
    "\n",
    "    def update_parameter(self, dataset, labels):\n",
    "        '''\n",
    "            Calculate the gradient and calculate new parameter value\n",
    "            \n",
    "            Input:\n",
    "                dataset - numpy array column of pixels\n",
    "                labels - numpy array column of label values\n",
    "                \n",
    "            Output:\n",
    "                updated parameter value\n",
    "            \n",
    "        '''\n",
    "        gradient = (labels * dataset * (1 - self.sigmoid(labels * (dataset @ self.w).reshape(-1,1)))).sum(axis=0).T\n",
    "        \n",
    "        return self.w + self.alpha * gradient\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        '''\n",
    "            Sigmoid function\n",
    "            \n",
    "            Input:\n",
    "                number or array of numbers\n",
    "            \n",
    "            Output:\n",
    "                result of sigmoid function with input as parameter, either number or array of numbers\n",
    "        '''\n",
    "                \n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def validate(self):\n",
    "        '''\n",
    "            Calculate accuracy score by segmenting validation set and comparing with mask\n",
    "            \n",
    "                Ouput: \n",
    "                    result - float accuracy score\n",
    "        '''\n",
    "\n",
    "        result = ((self.valset @ self.w) >= 0)\n",
    "        result = (result.astype(int) == self.vallabels[:,0])\n",
    "        result = result.sum() / self.valset.shape[0]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/jamessalem/Documents/ECE276A_PR1/trainset'\n",
    "mask_path = '/Users/jamessalem/Documents/ECE276A_PR1/masks'\n",
    "valimg_path = '/Users/jamessalem/Documents/ECE276A_PR1/valset'\n",
    "vallabel_path = '/Users/jamessalem/Documents/ECE276A_PR1/valmasks'\n",
    "\n",
    "my_logreg = LogisticRegression()\n",
    "my_logreg.load_data(dataset_path, mask_path, valimg_path, vallabel_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_logreg.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
